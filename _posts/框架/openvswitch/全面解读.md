---
title: OpenvSwitch（OVS）全面解读
date: 2019-08-22 17:09:22 
description: OpenvSwitch（OVS）全面解读 
categories:
- 框架
- openvswitch
tags: 
- openvswitch
export_on_save:
    markdown: true

  
---

## 1. 什么是Open vSwitch
OpenvSwitch简称OVS，正如其官网(http://openvswitch.org/)所述，OVS是一个高质量、多层的虚拟交换软件。它的目的是通过编程扩展支持大规模网络自动化，同时还支持标准的管理接口和协议。

随着虚拟化应用普及，需要部署更多的虚拟化交换机，而费用昂贵的闭源虚拟交换机让用户不堪重负，多层虚拟化软件交换机Open vSwitch由Nicira Networks开发，主要实现代码为可移植的C代码。它遵循Apache 2.0开源代码版权协议，可用于生产环境，支持跨物理服务器分布式管理、扩展编程、大规模网络自动化和标准化接口，实现了和大多数商业闭源交换机功能类似的软件交换机。

OVS官方的定位是要做一个产品级质量的多层虚拟交换机，通过支持可编程扩展来实现大规模的网络自动化。设计目标是方便管理和配置虚拟机网络，检测多物理主机在动态虚拟环境中的流量情况。针对这一目标，OVS具备很强的灵活性。可以在管理程序中作为软件switch运行，也可以直接部署到硬件设备上作为控制层。

如下图，在某台物理服务器中，运行着4台虚拟机，为了将这4台虚拟机在逻辑上组成我们需要的网络架构，于是就虚拟出了2台交换机，组成图中的网络架构。

这里写图片描述
![](https://raw.githubusercontent.com/jiangwei618/note/master/assets/image/1ovs_introdece.md-2019-08-08-13-44-14.png)

## 2. Open vSwitch架构与组件
简单来看，OVS由这三大部分构成：

这里写图片描述
![](https://raw.githubusercontent.com/jiangwei618/note/master/assets/image/1ovs_introdece.md-2019-08-08-13-44-40.png)

ovsdb-sever: OVS的数据库服务器，用来存储虚拟交换机的配置信息。它与manager和ovs-vswitchd交换信息使用了OVSDB(JSON-RPC)的方式。

ovs-vswitchd: OVS的核心部件，它和上层controller通信遵从openflow协议，它与ovsdb-server通信使用OVSDB协议，它和内核模块通过netlink通信，它支持多个独立的datapath（网桥），它通过更改flow table实现了绑定，和VLAN等功能。

ovs kernel module: OVS的内核模块，处理包交换和隧道，缓存flow，如果在内核的缓存中找到转发规则则转发，否则发向用户空间去处理。

有个OVS大概的了解，我们看看OVS到底由哪些模块组成，以及个模块的作用。如图：

这里写图片描述
![](https://raw.githubusercontent.com/jiangwei618/note/master/assets/image/1ovs_introdece.md-2019-08-08-13-44-47.png)
当前最新代码包主要包括以下模块和特性：

ovs-vswitchd： 主要模块，实现switch的daemon，包括一个支持流交换的Linux内核模块；
ovsdb-server： 轻量级数据库服务器，提供ovs-vswitchd获取配置信息，例如vlan、port等信息；
ovs-brcompatd： 让ovs-vswitch替换linux bridge，包括获取bridge ioctls的Linux内核模块；
ovs-dpctl：用来配置switch内核模块；
ovs-vsctl： 查询和更新ovs-vswitchd的配置；
ovs-appctl： 发送命令消息，运行相关daemon；
ovs-ofctl： 查询和控制OpenFlow交换机和控制器；
ovs-openflowd：一个简单的OpenFlow交换机；
ovs-controller：一个简单的OpenFlow控制器；
ovs-pki：OpenFlow交换机创建和管理公钥框架；
ovs-tcpundump：tcpdump的补丁，解析OpenFlow的消息；
ovs-bugtool：管理openvswitch的bug信息。

这里写图片描述
![](https://raw.githubusercontent.com/jiangwei618/note/master/assets/image/1ovs_introdece.md-2019-08-08-13-44-58.png)

· ovs-vswitchd 为主要模块，实现交换机的守护进程daemon
在Openvswitch所在的服务器进行ps aux可以看到以下的进程

root 1008 0.1 0.8 242948 31712 ? Svconsole:emer="" -vfile:info="" -vsyslog:err="" 32:17="" aug06="" db.sock="" openvswitch="" ovs-vswitchd="" pre="" run="" unix:="" var="">
注意这里ovs-vswitchd监听了一个本机的db.sock文件

· openvswitch.ko为Linux内核模块，支持数据流在内核的交换
我们使用lsmod列举加载到内核的模块：

~# lsmod | grep openvswitch
openvswitch 66901 0
gre 13808 1 openvswitch
vxlan 37619 1 openvswitch
libcrc32c 12644 2 btrfs,openvswitch

· ovsdb-server 轻量级数据库服务器，保存配置信息，ovs-vswitchd通过这个数据库获取配置信息

通过ps aux可以看到如下进程：


root 985 0.0 0.0 21172 2120 ? S< Aug06 1:20 ovsdb-server /etc/openvswitch/conf.db -vconsole:emer -vsyslog:err -vfile:info --remote=punix:/var/run/openvswitch/db.sock --private-key=db:Open_vSwitch,SSL,private_key --certificate=db:Open_vSwitch,SSL,certificate --bootstrap-ca-cert=db:Open_vSwitch,SSL,ca_cert --no-chdir --log-file=/var/log/openvswitch/ovsdb-server.log --pidfile=/var/run/openvswitch/ovsdb-server.pid --detach –monitor

可以看出，ovsdb-server将配置信息保存在conf.db中，并通过db.sock提供服务，ovs-vswitchd通过这个db.sock从这个进程读取配置信息。


/etc/openvswitch/conf.db是json格式的，可以通过命令ovsdb-client dump将数据库结构打印出来。数据库结构包含如下的表格：

这里写图片描述
![](https://raw.githubusercontent.com/jiangwei618/note/master/assets/image/1ovs_introdece.md-2019-08-08-13-45-13.png)

数据库结构如下：
![](https://raw.githubusercontent.com/jiangwei618/note/master/assets/image/1ovs_introdece.md-2019-08-08-13-45-19.png)


通过ovs-vsctl创建的所有的网桥，网卡，都保存在数据库里面，ovs-vswitchd会根据数据库里面的配置创建真正的网桥，网卡。


相关命令

ovs-dpctl 用来配置switch内核模块。

ovs-vsctl 查询和更新ovs-vswitchd的配置。

ovs-appctl 发送命令消息，运行相关daemon。

ovs-ofctl 查询和控制OpenFlow交换机和控制器。


## 3. 工作流程

这里写图片描述
![](https://raw.githubusercontent.com/jiangwei618/note/master/assets/image/1ovs_introdece.md-2019-08-08-13-45-31.png)

一般的数据包在linux网络协议栈中的流向为黑色箭头流向：

从网卡上接受到数据包后层层往上分析，最后离开内核态，把数据传送到用户态。当然也有些数据包只是在内核网络协议栈中操作，然后再从某个网卡发出去。


但当其中有openVswitch时，数据包的流向就不一样了：

首先是创建一个网桥：ovs-vsctl add-br br0；然后是绑定某个网卡：ovs-vsctl add-port br0 eth0；这里默认为绑定了eth0网卡。

数据包的流向是从网卡eth0上然后到openVswitch的端口vport上进入openVswitch中，然后根据key值进行流表的匹配。如果匹配成功，则根据流表中对应的action找到其对应的操作方法，完成相应的动作（这个动作有可能是把一个请求变成应答，也有可能是直接丢弃，也可以自己设计自己的action）；如果匹配不成功，则执行默认的动作，有可能是放回内核网络协议栈中去处理（在创建网桥时就会相应的创建一个端口连接内核协议栈的）。


在工作中一般在这几个地方来修改内核代码以达到自己的目的：

第一个是在datapath.c中的ovs_dp_process_received_packet(struct vport *p, struct sk_buff *skb)函数内添加相应的代码来达到自己的目的，因为对于每个数据包来说这个函数都是必经之地；

第二个就是自己去设计自己的流表了；可以根据流表来设计自己的action，完成自己想要的功能。


## 4. 术语与逻辑概念

在Openvswitch的使用中，为了能全面地理解Openvswitch的内部原理，我们需要对其中的术语和概念有所了解。


Bridge：即网桥，在Openvswitch中每个虚拟交换机（vswitch）都可以认为是一个网桥，因为Openvswitch在底层的通信是借助了网桥模块来实现的，同时我们通过brctl也能查看到ovs所创建的网桥设备。


这里写图片描述
![](https://raw.githubusercontent.com/jiangwei618/note/master/assets/image/1ovs_introdece.md-2019-08-08-13-45-39.png)

这里写图片描述
![](https://raw.githubusercontent.com/jiangwei618/note/master/assets/image/1ovs_introdece.md-2019-08-08-13-45-44.png)

Datapath：即数据通路，在Openvswitch中每个Bridge我们都可以理解为Datapath，也就是说Datapath就是虚拟交换机。


这里写图片描述
![](https://raw.githubusercontent.com/jiangwei618/note/master/assets/image/1ovs_introdece.md-2019-08-08-13-45-51.png)

如上图，每个Datapath项中我们都能看到存在几个Port项，它们其实就是虚拟交换机（datapath）上的端口。如上br-tun项中，port2就与远端的端口建立了gre隧道。


Flowtable：即数据流表，根据之前对OpenFlow的介绍，我们已经了解了Openvswitch中利用openflow协议在实现虚拟交换机，而数据流表就是提供给Bridge/Datapath做数据操作的指令。


Port：即端口，这里的端口是指虚拟交换机逻辑上的接口，我们可以通过ovs-vsctl命令查看各个网桥（即虚拟交换机）上的接入的端口。


这里写图片描述
![](https://raw.githubusercontent.com/jiangwei618/note/master/assets/image/1ovs_introdece.md-2019-08-08-13-47-26.png)

Patch：即连线，我们可以理解为传统交换机的Trunk，在这里就是网络节点和运算节点间ovs虚拟交换的联结。


下图为网络节点的br-int（用于VM的虚拟交换）。


这里写图片描述
![](https://raw.githubusercontent.com/jiangwei618/note/master/assets/image/1ovs_introdece.md-2019-08-08-13-47-14.png)


下图为运算节点上的br-int，我们可以看到其中一个端口（vport）是和网络节点的br-int交换进行联结的。它们的类型为“type:patch”，这样的联结就是Patch。


这里写图片描述
![](https://raw.githubusercontent.com/jiangwei618/note/master/assets/image/1ovs_introdece.md-2019-08-08-13-47-48.png)

Tun/Tap：它们是Linux/Unix系统中的虚拟网络设备，TAP等同于以太网设备，操作L2层数据链路层的数据帧；TUN则是模拟L3网络层的设备，操作网络层的IP数据包。


在OVS中，其GRE隧道模式在底层的实现是由TUN支持的，而TAP设备则是用来分隔openvswitch中不同的subnet。


如下图，网络节点上两个TAP设备接入在br-int虚拟交换机中。


这里写图片描述
![](https://raw.githubusercontent.com/jiangwei618/note/master/assets/image/1ovs_introdece.md-2019-08-08-13-47-57.png)


这里写图片描述
![](https://raw.githubusercontent.com/jiangwei618/note/master/assets/image/1ovs_introdece.md-2019-08-08-13-48-03.png)

我们可以看到两个TAP设备的IP地址是在Openvswitch中创建的2个subnet网络的网关地址。


Vnet：即虚拟机的虚拟网卡，在运算节点上可以看到OVS对于vnet的管理和传统的网桥模式不同，根据对设备物理地址的判断，应该是OVS采用了相应的tunneling技术。


这里写图片描述
![](https://raw.githubusercontent.com/jiangwei618/note/master/assets/image/1ovs_introdece.md-2019-08-08-13-48-10.png)

这里写图片描述
![](https://raw.githubusercontent.com/jiangwei618/note/master/assets/image/1ovs_introdece.md-2019-08-08-13-48-14.png)
